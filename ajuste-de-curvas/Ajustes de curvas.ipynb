{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de curvas:\n",
    "\n",
    "O ajuste de curvas é um procedimento no qual uma fórmula matemática é usada pra produzir uma curva que melhor represente um conjunto de dados. A função não tem que fornecer o valor exato em cada ponto, mas sim representar o conjunto de dados de forma satisfatória como um todo.\n",
    "\n",
    "O ajuste de curvas é tipicamente utilizado quando os valores dos dados medidos apresentam algum erro ou dispersão.\n",
    "\n",
    "#### Ajuste de curvas com equações lineares:\n",
    "\n",
    "O ajuste de curvas usando uma equação linear (polinômio de primeiro grau) é o processo pelo qual uma equação na forma:\n",
    "\n",
    "$$\n",
    "    y = a_1 x + a_0 \\hspace1cm (1)\n",
    "$$\n",
    "\n",
    "É usada pra promover o melhor ajuste de um conjunto de pontos. Isso é feito com a determinação das constantes a1 e a0 que fornecem o menor erro quando os pontos medidos são substituíudos na Eq. (1).\n",
    "\n",
    "##### Medição da qualidade de um ajuste:\n",
    "\n",
    "Um critério que mede o quão bem uma função pode representar de forma aproximada um conjunto de dados é um número que quantifica a concordância geral entre os pontos pertencentes a esse conjunto de dados e a função utilizada. Ela pode ser usado para comparar duas funções diferentes usadas no ajuste do mesmo conjunto de dados e pode ser usado para determinar os coeficientes da função que levem ao melhor ajuste.\n",
    "\n",
    "O ajuste entre um conjunto de dados e uma função linear aproximada é determinado primeiramente com o cálculo do erro (Resíduo), a diferença entre cada ponto pertecente ao conjunto de dados e o valor da função aproximada. Os resíduos são usados para calcular o erro total em todos os pontos,\n",
    "\n",
    "O resíduo ri em um ponto (xi,yi) é a diferença entre o valor yi do ponto medido e do valor da função f(xi) usada para aproximar o conjunto de dados:\n",
    "\n",
    "$$\n",
    "    r_i = y_i - f(x_i) \\hspace1cm (2)\n",
    "$$\n",
    "\n",
    "Uma definição para o erro gloval E que fornece uma boa medida do erro total e que também pode ser usada para determinar uma única função linear que leve ao melhor ajuste é obtida fazendo com que E seja igual à soma dos quadrados dos resíduos:\n",
    "\n",
    "$$\n",
    "    E = \\sum^{n}_{i=1} r^{2}_{i} = \\sum^{n}_{i=1}[y_i - (a_1 x_i + a_0)]^{2} \\hspace1cm (3)\n",
    "$$\n",
    "\n",
    "##### Regressão linear por mínimos quadrados:\n",
    "\n",
    "A regressão linear por mínimos quadrados é um procedimento no qual os coeficientes a1 e a0 da função linear y = a1x + a0 são determinados de tal forma que essa função leve ao melhor ajuste de um determinado conjunto de pontos. O melhor ajuste é definido como o menor erro total calculado com a soma dos quadrados dos resíduos.\n",
    "\n",
    "Para um dado conjunto de n ponto (xi,yi), o erro gloval calculado é:\n",
    "\n",
    "$$\n",
    "    E = \\sum^{n}_{i=1}[y_i - (a_1 x_i + a_0)]^{2} \\hspace1cm (4)\n",
    "$$\n",
    "\n",
    "A função E tem um mínimo nos valores de a1 e a0 nos quais as derivadas parciais de E em relação a cada variável são iguais a zero. Calculando as derivadas parciais e as igualando a zero, obtém-se:\n",
    "\n",
    "$$\n",
    "    \\frac{\\delta E}{\\delta a_0} = -2 \\sum^{n}_{i=1} (y_i - a_1 x_i - a_0) = 0 \\hspace1cm (5)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\frac{\\delta E}{\\delta a_1} = -2 \\sum^{n}_{i=1} (y_i - a_1 x_i - a_0)x_i = 0 \\hspace1cm (6)\n",
    "$$\n",
    "\n",
    "As equações (5) e (6) formam um sistema de duas equações lineares com incógnitas a1 e a0 e podem ser escritas na forma:\n",
    "\n",
    "$$\n",
    "    n a_0 + (\\sum^{n}_{i=1}x_i)a_1 = \\sum^{n}_{i=1} y_i \\hspace1cm (7)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    (\\sum^{n}_{i=1}x_i)a_0 + (\\sum^{n}_{i=1}x^{2}_{i})a_1 = \\sum^{n}_{i=1} x_i y_i \\hspace1cm (8)\n",
    "$$\n",
    "\n",
    "A solução do sistema contêm somas idênticas, é conveniente calculá-las primeiramente para então substituí-las nas equações. Tais somas são definidas como:\n",
    "\n",
    "$$\n",
    "    S_x = \\sum^{n}_{i=1} x_i,\\hspace0.5cmS_y = \\sum^{n}_{i=1} y_i,\\hspace0.5cmS_{xy} = \\sum^{n}_{i=1} x_i y_i,\\hspace0.5cmS_{xx} = \\sum^{n}_{i=1} x^{2}_{i}\\hspace0.5cm (9)\n",
    "$$\n",
    "\n",
    "Com essas definições, as equações dos coeficientes a1 e a0 são:\n",
    "\n",
    "$$\n",
    "    a_1 = \\frac{nS_{xy}-S_x S_y}{nS_{xx} - (S_x)^2} \\hspace1cm a_0 = \\frac{S_{xx}S_y - S_{xy}S_x}{nS_{xx}-(S_x)^2}\n",
    "$$\n",
    "\n",
    "##### Escrevendo uma equação não-linear em uma forma linear:\n",
    "\n",
    "Para que a regressão linear possa ser utilizada, a equação não-linear de duas variáveis deve ser modificada de tal forma que a nova equação seja linear com termos contendo as variáveis originais.\n",
    "\n",
    "<img src='img/img-1.png'>\n",
    "\n",
    "\n",
    "#### Regressão polinomial:\n",
    "\n",
    "A regressão polinomial é um procedimento usado na determinação dos coeficiente de um polinômio de segundo grau, ou de ordem maior, de forma que esse polinômio produza o melhor ajuste de um determinado conjunto de dados. A dedução das equações utilizadas para determinar os coeficientes se baseia na minimização do erro total.\n",
    "\n",
    "Se o polinômio de ordem _m_ usado no ajuste da curva é:\n",
    "\n",
    "$$\n",
    "    f(x) = a_m x^m + a_{m-1}x^{m-1} + ... + a_1 x^i + a_0 \\hspace1cm (10)\n",
    "$$\n",
    "\n",
    "Então, para um dado conunto de n ponto (xi, yi) (m é menor que n-1), o erro total calculado é:\n",
    "\n",
    "$$\n",
    "    E = \\sum^{n}_{i=1} [y_i - (a_m x^m + a_{m-1}x^{m-1} + ... + a_1 x^i + a_0)]^2 \\hspace1cm (11)\n",
    "$$\n",
    "\n",
    "Como todos os valores de xi e yi são conhecidos, o erro E é um função não linear das m + 1 variáveis (a0 a am). A função E tem um mínimo nos valores de a0 a am nos quais as derivadas parciais de E em relação a cada uma das variáveis são iguais a zero. Calculando as derivadas parciais de E e as igualando a zero, obtém-se um conjunto de m+1 equações lineares para os coeficientes.\n",
    "\n",
    "Como exemplo, para o caso m=2:\n",
    "\n",
    "$$\n",
    "    E = \\sum^{n}_{i=1} [y_i - (a_2 x^2_i + a_1 x_i + a_0)]^2 \\hspace1cm (12)\n",
    "$$\n",
    "\n",
    "Calculando as derivadas parviais em relação a a0, a1 e a2 e igualando os resultados a zero, obtém-se:\n",
    "\n",
    "$$\n",
    "    \\frac{\\delta E}{\\delta a_0} = -2 \\sum^{n}_{i=1} (y_i - a_2 x^2_i - a_1 x_i - a0) = 0 \\hspace1cm (13)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\frac{\\delta E}{\\delta a_1} = -2 \\sum^{n}_{i=1} (y_i - a_2 x^2_i - a_1 x_i - a_0)x_i = 0 \\hspace1cm (14)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\frac{\\delta E}{\\delta a_2} = -2 \\sum^{n}_{i=1} (y_i - a_2 x^2_i - a_1 x_i - a_0)x^2_i = 0 \\hspace1cm (15)\n",
    "$$\n",
    "\n",
    "As equações 13 a 15 formam um sistema de três equações lineares em função das incógnitas a0, a1 e a2, que pode ser reescrito na forma:\n",
    "\n",
    "$$\n",
    "    Sa = s \\rightarrow \\begin{pmatrix} n & S_x & S_{x^2} \\\\ S_x & S_{x^2} & S_{x^3} \\\\ S_{x^2} & S_{x^3} & S_{x^4} \\end{pmatrix} \\times \\begin{pmatrix} a_0 \\\\ a_1 \\\\ a_2 \\end{pmatrix} = \\begin{pmatrix} S_x \\\\ S_{xy} \\\\ S_{x^2y} \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "A solução do sistema de equações fornece os valores dos coeficientes a0, a1 e a2 do polinômio que melhor se ajusta aos n ponto (xi, yi)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algoritmos:\n",
    "\n",
    "- Importações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Algoritmos auxiliares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussJordan(A, b, dim, rec=True):\n",
    "    \n",
    "    # Imprimindo dados de entrada:\n",
    "    print('Matriz A com dimensão: {0}'.format(dim))\n",
    "    print(A, '\\n')\n",
    "    print('Vetor b:\\n{0}\\n'.format(b))\n",
    "    \n",
    "    # Unindo as matrizes no formato [A b]\n",
    "    A = np.insert(A, dim, b, axis=1)\n",
    "    print('Nova matriz no formato [A b]:')\n",
    "    print(A, '\\n')\n",
    "    \n",
    "    # Pivôtação:\n",
    "    for i in range(0, dim):\n",
    "        if A[i,i] == 0:\n",
    "            print('A linha {0} ( {1} ) não pode ser a linha pivô (coeficiente zero)'.format(i, A[i]))\n",
    "            for j in range(i + 1, dim):\n",
    "                if A[j][i] != 0:\n",
    "                    print('Troca: linha {0} ({1}) -> linha {2} ({3})\\n'.format(i,A[i],j,A[j]))\n",
    "                    linhaTemp = A[i].copy()\n",
    "                    A[i] = A[j]\n",
    "                    A[j] = linhaTemp\n",
    "                    print('Nova matriz pós pivôtação:')\n",
    "                    print(A, '\\n\\n')\n",
    "                    break\n",
    "        \n",
    "        # Fim da pivotação\n",
    "        print('Operações em linhas:\\n\\n')\n",
    "        A[i] = A[i]/A[i,i]\n",
    "        print('A[{0}] = A[{0}]/A[{0},{0}] = {1}\\n'.format(i, A[i]))\n",
    "        for k in range(0, dim):\n",
    "            if k != i and A[k,i] != 0:\n",
    "                A[k] = A[k] - A[i]*A[k,i]\n",
    "                print('A[{0}] = A[{0}] - A[{1}]*A[{0},{1}] = {2}'.format(k, i, A[k]))\n",
    "        print('\\nNova Matriz: \\n', A, '\\n\\n')\n",
    "                \n",
    "            \n",
    "    # Recuperando os valores de b e A\n",
    "    if rec :\n",
    "        for i in range(0, dim):\n",
    "            b[i] = A[i][dim]\n",
    "        \n",
    "        A = np.delete(A, dim, 1)\n",
    "    \n",
    "        return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regressão linear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regLin(x,y):\n",
    "    \n",
    "    #Definindo o tamanho dos vetores:\n",
    "    if x.size != y.size:\n",
    "        print('Vetores de tamanhos diferentes!')\n",
    "        print('xn: {0}\\nyn: {1}'.format(x.size,y.size))\n",
    "        return None, None\n",
    "    else:\n",
    "        n = x.size\n",
    "    \n",
    "    # Definindo os somatórios:\n",
    "    Sx, Sy, Sxy, Sxx = np.sum(x), np.sum(y), np.sum(x*y), np.sum(x**2)\n",
    "    print('\\nSomatórios:')\n",
    "    print('Sx: {}\\nSy: {}\\nSxy: {}\\nSxx: {}\\n'.format(Sx,Sy,Sxy,Sxx))\n",
    "    \n",
    "    # Definindo os coeficiente a0 e a1:\n",
    "    \n",
    "    dem = n*Sxx - Sx**2\n",
    "    \n",
    "    a1 = (n*Sxy - Sx*Sy)/dem\n",
    "    a0 = (Sxx*Sy - Sxy*Sx)/dem\n",
    "    \n",
    "    print('a1 = {:.4f}*{:.4f} - {:.4f}*{:.4f} / {:.4f}*{:.4f} - {:.4f}^2 = {:.4f}'.format(n,Sxy,Sx,Sy,n,Sxx,Sx,a1))\n",
    "    print('a0 = {:.4f}*{:.4f} - {:.4f}*{:.4f} / {:.4f}*{:.4f} - {:.4f}^2 = {:.4f}'.format(Sxx,Sy,Sxy,Sx,n,Sxx,Sx,a0))\n",
    "    \n",
    "    return a1, a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste do algoritmo:\n",
    "\n",
    "# Determinar os coeficientes m e b da equação y = mx/b + x\n",
    "\n",
    "x=np.array([0.34440,0.42975,0.48713,0.70243,0.77597]);\n",
    "y=np.array([142, 147, 153, 149, 153]);\n",
    "\n",
    "a1, a0 = regLin(x,y)\n",
    "\n",
    "n = a1/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regressão polinômial (segunda ordem):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regPoli2(x,y):\n",
    "    \n",
    "    #Definindo o tamanho dos vetores:\n",
    "    if x.size != y.size:\n",
    "        print('Vetores de tamanhos diferentes!')\n",
    "        print('xn: {0}\\nyn: {1}'.format(x.size,y.size))\n",
    "        return None, None, None\n",
    "    else:\n",
    "        n = x.size\n",
    "    \n",
    "    # Definindo somatórios necessários:\n",
    "    Sx, Sy, Sx2, Sx3, Sx4, Sxy, Sx2y = np.sum(x), np.sum(y), np.sum(x**2), np.sum(x**3), np.sum(x**4), np.sum(x*y), np.sum((x**2)*y)\n",
    "    print('Definindo elementos das matrizes:')\n",
    "    print('- Matriz S:')\n",
    "    print('n: {}\\nSx: {}\\nSx2: {}\\nSx3: {}\\nSx4: {}\\n'.format(n,Sx,Sx2,Sx3,Sx4))\n",
    "    print('- Vetor s:')\n",
    "    print('Sy: {}\\nSxy: {}\\nSx2y: {}\\n'.format(Sy,Sxy,Sx2y))\n",
    "    \n",
    "    # Monstando as matrizes de equações:\n",
    "    S = np.array([\n",
    "        [n, Sx, Sx2],\n",
    "        [Sx, Sx2, Sx3],\n",
    "        [Sx2, Sx3,Sx4]\n",
    "    ])\n",
    "    \n",
    "    print('Matriz S:')\n",
    "    print(S,'\\n')\n",
    "    \n",
    "    s = np.array([Sy, Sxy, Sx2y])\n",
    "    \n",
    "    print('Array s:')\n",
    "    print(s,'\\n')\n",
    "    \n",
    "    # Calculando os coeficientes:\n",
    "    \n",
    "    a = gaussJordan(S, s, 3)\n",
    "    #a = np.linalg.inv(S)@s\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste do algoritmo:\n",
    "\n",
    "x=np.array([1., 3, 5, 7, 10]);\n",
    "y=np.array([2.2, 5, 5.5, 6.1, 6.6]);\n",
    "\n",
    "regPoli2(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
